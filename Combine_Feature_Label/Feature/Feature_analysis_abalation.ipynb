{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "718c0636-56f4-4b0d-842d-42faf4068316",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting shap\n",
      "  Downloading shap-0.46.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.15.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.6.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.67.1)\n",
      "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (24.2)\n",
      "Collecting slicer==0.0.8 (from shap)\n",
      "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.61.0)\n",
      "Collecting cloudpickle (from shap)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.44.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->shap) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2025.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Downloading shap-0.46.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (540 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.1/540.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: slicer, cloudpickle, shap\n",
      "Successfully installed cloudpickle-3.1.1 shap-0.46.0 slicer-0.0.8\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5035e78c-2e1d-41fc-9985-83a988a194cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import shap\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"processed_dataset_with_clusters.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and target variables\n",
    "feature_columns = df.columns[:-5]  # Excluding the last 5 columns (target variables)\n",
    "target_columns = df.columns[-5:]  # Last 5 columns are target variables\n",
    "features = df[feature_columns]\n",
    "\n",
    "# Normalize features using StandardScaler (Z-score normalization)\n",
    "scaler = StandardScaler()\n",
    "normalized_features = scaler.fit_transform(features)\n",
    "df_normalized = pd.DataFrame(normalized_features, columns=feature_columns)\n",
    "\n",
    "# Define sensor modalities\n",
    "modalities = {\n",
    "    \"HRV\": [col for col in feature_columns if \"hrv\" in col],\n",
    "    \"ACC\": [col for col in feature_columns if \"acc\" in col],\n",
    "    \"EDA\": [col for col in feature_columns if \"eda\" in col]\n",
    "}\n",
    "\n",
    "# Initialize results dictionary\n",
    "feature_analysis_results = {}\n",
    "modality_importance = {}\n",
    "\n",
    "# Analyze each target variable\n",
    "for target_variable in target_columns:\n",
    "    # Compute correlation with the target variable\n",
    "    correlations = df_normalized.corrwith(df[target_variable]).abs().sort_values(ascending=False)\n",
    "\n",
    "    # Compute mutual information between features and target\n",
    "    mi_scores = mutual_info_regression(df_normalized, df[target_variable], random_state=42)\n",
    "\n",
    "    # Train a simplified Random Forest model to assess feature importance\n",
    "    rf = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "    rf.fit(df_normalized, df[target_variable])\n",
    "    feature_importance = rf.feature_importances_\n",
    "\n",
    "    # SHAP analysis\n",
    "    explainer = shap.TreeExplainer(rf)\n",
    "    shap_values = explainer.shap_values(df_normalized)\n",
    "\n",
    "    # Store results in a DataFrame\n",
    "    feature_analysis = pd.DataFrame({\n",
    "        \"Feature\": feature_columns,\n",
    "        \"Correlation\": correlations.values,\n",
    "        \"RandomForestImportance\": feature_importance,\n",
    "        \"MutualInfo\": mi_scores,\n",
    "        \"SHAP_Mean\": np.abs(shap_values).mean(axis=0)\n",
    "    })\n",
    "\n",
    "    # Sort by Random Forest feature importance\n",
    "    feature_analysis = feature_analysis.sort_values(by=\"RandomForestImportance\", ascending=False)\n",
    "    feature_analysis_results[target_variable] = feature_analysis\n",
    "\n",
    "    # Aggregate feature importance by modality\n",
    "    modality_scores = {\n",
    "        modality: feature_analysis[feature_analysis[\"Feature\"].isin(features)][\"RandomForestImportance\"].sum() for\n",
    "        modality, features in modalities.items()}\n",
    "    modality_importance[target_variable] = modality_scores\n",
    "\n",
    "# Display results\n",
    "for target, analysis_df in feature_analysis_results.items():\n",
    "    print(f\"Feature Importance for {target}:\")\n",
    "    print(analysis_df.head(10))  # Show top 10 most important features\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Display modality-level importance\n",
    "modality_importance_df = pd.DataFrame(modality_importance)\n",
    "print(\"Modality-Level Feature Importance:\")\n",
    "print(modality_importance_df)\n",
    "\n",
    "# Compute and visualize correlation matrix between different modalities\n",
    "modality_corr = df_normalized[[col for col_list in modalities.values() for col in col_list]].corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(modality_corr, cmap='coolwarm', center=0)\n",
    "plt.title(\"Correlation Matrix Between Modalities\")\n",
    "plt.show()\n",
    "\n",
    "# Optional: Visualize feature distributions before normalization\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "fig.suptitle(\"Feature Distributions Before Normalization\", fontsize=16)\n",
    "\n",
    "# Selecting a subset of features to plot\n",
    "sample_features = features.columns[:9]\n",
    "\n",
    "for i, col in enumerate(sample_features):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    sns.histplot(features[col], bins=50, kde=True, ax=ax)\n",
    "    ax.set_title(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95396964-1171-400d-993a-64f850a58285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
