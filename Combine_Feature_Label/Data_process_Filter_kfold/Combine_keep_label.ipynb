{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e2c931e-f804-4b1d-abec-2eb8a5ea666b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Combined_model_performance_by_label.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# File paths\n",
    "file_paths = {\n",
    "    \"fold_transformed_LGBM_XGB\": \"fold_transformed_LGBM_XGB_model_performance_results.csv\",\n",
    "    \"fold_model_transformed\": \"fold_model_transformed_performance_results.csv\",\n",
    "    \"fold_LGBM_XGB\": \"fold__LGBM_XGB_model_performance_results.csv\",\n",
    "    \"fold_model\": \"fold_model_performance_results.csv\"\n",
    "}\n",
    "\n",
    "# Load data\n",
    "dataframes = {name: pd.read_csv(path) for name, path in file_paths.items()}\n",
    "\n",
    "# Standardize dataset column names and assign default values for missing datasets\n",
    "for key, df in dataframes.items():\n",
    "    if \"Data Type\" in df.columns:\n",
    "        df.rename(columns={\"Data Type\": \"Dataset\"}, inplace=True)\n",
    "    elif \"DataType\" in df.columns:\n",
    "        df.rename(columns={\"DataType\": \"Dataset\"}, inplace=True)\n",
    "    else:\n",
    "        df[\"Dataset\"] = \"original\"  # Assign \"original\" to missing dataset types\n",
    "    \n",
    "    # Rename \"RF\" to \"Random Forest\"\n",
    "    df[\"Model\"] = df[\"Model\"].replace(\"RF\", \"Random Forest\")\n",
    "    \n",
    "    # Clean up Label column by removing text within parentheses\n",
    "    df[\"Label\"] = df[\"Label\"].apply(lambda x: re.sub(r\"\\s*\\(.*?\\)\", \"\", x))\n",
    "\n",
    "# Define relevant metric columns\n",
    "metric_columns = [\"accuracy\", \"precision\", \"recall\", \"f1_score\", \"threshold_accuracy\", \"top_3_accuracy\"]\n",
    "\n",
    "# Function to process each dataframe\n",
    "def process_dataframe_with_labels(df):\n",
    "    # Calculate the mean and std across the 5 folds for each Label, Model, and Dataset type\n",
    "    avg_metrics = df.groupby([\"Label\", \"Model\", \"Dataset\"])[metric_columns].agg([\"mean\", \"std\"]).reset_index()\n",
    "    return avg_metrics\n",
    "\n",
    "# Process all files\n",
    "processed_dfs = {key: process_dataframe_with_labels(df) for key, df in dataframes.items()}\n",
    "\n",
    "# Concatenate all processed dataframes\n",
    "all_data_with_labels = pd.concat(processed_dfs.values(), ignore_index=True)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "output_file = \"Combined_model_performance_by_label.csv\"\n",
    "all_data_with_labels.to_csv(output_file, index=False)\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8656b99c-5e04-4174-b2b2-f8712ed14763",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
